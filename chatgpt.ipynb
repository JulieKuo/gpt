{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = api_key\n",
    "\n",
    "response = openai.Completion.create(\n",
    "model = \"text-davinci-003\",\n",
    "prompt = \"請用python印出1到10。\",\n",
    "temperature = 0.75,\n",
    "max_tokens = 1500,\n",
    ")\n",
    "\n",
    "response1 = response['choices'][0]['text'].lstrip(\"\\n\")\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def get_query(root, query_path, data_path):\n",
    "    # logging.info(f\"Get query.\")\n",
    "\n",
    "    query_path = os.path.join(root, query_path)\n",
    "    data_path = os.path.join(root, data_path)\n",
    "\n",
    "    with open(query_path, 'r', encoding = \"utf-8\") as f:\n",
    "        prompt = f.read()\n",
    "\n",
    "    prompt += f\"\\n\\n資料存檔的絕對路徑為{data_path}。\"\n",
    "\n",
    "    prompt = prompt.replace(\n",
    "        \"資料期間:無\",\n",
    "        f\"用sys.argv接收命令列參數:\\n    1. 起始時間\\n    2. 結束時間\"\n",
    "        )\n",
    "\n",
    "    # logging.info(f\"<< Question >>\\n{prompt}\")\n",
    "\n",
    "    return prompt\n",
    "\n",
    "root = \"C:\\\\Users\\\\tzuli\\\\Documents\\\\python\\\\chatgpt\"\n",
    "query_path = \"query\\\\query3.txt\"\n",
    "data_path = \"data\\\\data3.csv\"\n",
    "query = get_query(root, query_path, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "# Load the tokenizer.\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "n_tokens = len(tokenizer.encode(query))\n",
    "n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.system(\"which python\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 17-18: truncated \\UXXXXXXXX escape (3970544258.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[10], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    print('''.\\gen_exe.bat \"C:\\Users\\tzuli\\Documents\\python\\chatgpt\\result\" \"C:\\Users\\tzuli\\Documents\\python\\chatgpt\\requirement\\requirements.txt\" \"C:\\Users\\tzuli\\Documents\\python\\chatgpt\\response\\response3.py\"''')\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 17-18: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "print('''.\\gen_exe.bat \"C:/Users/tzuli/Documents\\python\\chatgpt\\result\" \"C:\\Users\\tzuli\\Documents\\python\\chatgpt\\requirement\\requirements.txt\" \"C:\\Users\\tzuli\\Documents\\python\\chatgpt\\response\\response3.py\"''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config(config_path = \"./config.json\")\n",
    "\n",
    "root = config[\"root\"]\n",
    "query_path = root + \"/\" + config[\"query_path\"]\n",
    "data_path = root + \"/\" + config[\"data_path\"]\n",
    "query_venv_path = root + \"/\" + config[\"query_venv_path\"]\n",
    "python_path = root + \"/\" + config[\"python_path\"]\n",
    "requirements_path = root + \"/\" + config[\"requirements_path\"]\n",
    "result_path = root + \"/\" + config[\"result_path\"]\n",
    "api_key = config[\"api_key\"]\n",
    "log_path = root + \"/\" + config[\"log_path\"]\n",
    "exe_log_path = root + \"/\" + config[\"exe_log_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\gen_exe.bat \"C:/Users/tzuli/Documents/python/chatgpt/result\" \"C:/Users/tzuli/Documents/python/chatgpt/requirement/requirements.txt\" \"C:/Users/tzuli/Documents/python/chatgpt/response/response3.py\" \"C:/Users/tzuli/Documents/python/chatgpt/logs/gen_exe.log\"\n"
     ]
    }
   ],
   "source": [
    "print(f'.\\gen_exe.bat \"{result_path}\" \"{requirements_path}\" \"{python_path}\" \"{exe_log_path}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from log_config import Log\n",
    "import json, os, openai\n",
    "\n",
    "\n",
    "\n",
    "def read_config(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "\n",
    "\n",
    "def get_query(query_path, data_path, query_venv_path):\n",
    "    logging.info(f\"Get query.\")\n",
    "\n",
    "    with open(query_path, 'r', encoding = \"utf-8\") as f:\n",
    "        prompt1 = f.read()\n",
    "\n",
    "    with open(query_venv_path, 'r', encoding = \"utf-8\") as f:\n",
    "        prompt2 = f.read()\n",
    "\n",
    "    prompt1 += f\"\\n    資料存檔的絕對路徑為{data_path}。\\n\\n\"\n",
    "\n",
    "    prompt1 = prompt1.replace(\n",
    "        \"資料期間:無\",\n",
    "        f\"用sys.argv接收命令列參數:\\n    1. 起始時間\\n    2. 結束時間\"\n",
    "        )\n",
    "    prompt1 += prompt2\n",
    "\n",
    "    logging.info(f\"<< Question >>\\n{prompt1}\")\n",
    "\n",
    "    return prompt1\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def connect_gpt(openai, api_key, prompt):\n",
    "    openai.api_key = api_key\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "    model = \"text-davinci-003\",\n",
    "    prompt = prompt,\n",
    "    temperature = 0.8,\n",
    "    max_tokens = 3000,\n",
    "    )\n",
    "\n",
    "    response1 = response['choices'][0]['text'].lstrip(\"\\n\")\n",
    "    code, requirements = response1.split(\"\\n2.\")\n",
    "    code = code.replace(\"1.\", \"\").lstrip(\"\\n\").rstrip(\"\\n\")\n",
    "    requirements = requirements.lstrip(\"\\n\")\n",
    "\n",
    "    return code, requirements\n",
    "\n",
    "\n",
    "\n",
    "def save_file(code, requirements, python_path, requirements_path):\n",
    "    logging.info(f\"Save response python file.\")\n",
    "\n",
    "    with open(python_path, 'w', encoding = \"utf-8\") as f:\n",
    "        f.write(code)\n",
    "    \n",
    "    with open(requirements_path, 'w', encoding = \"utf-8\") as f:\n",
    "        f.write(requirements)\n",
    "\n",
    "    logging.info(f\"Finish!\")\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    config = read_config(config_path = \"./config.json\")\n",
    "\n",
    "    root = config[\"root\"]\n",
    "    query_path = root + \"/\" + config[\"query_path\"]\n",
    "    data_path = root + \"/\" + config[\"data_path\"]\n",
    "    query_venv_path = root + \"/\" + config[\"query_venv_path\"]\n",
    "    python_path = root + \"/\" + config[\"python_path\"]\n",
    "    requirements_path = root + \"/\" + config[\"requirements_path\"]\n",
    "    result_path = root + \"/\" + config[\"result_path\"]\n",
    "    api_key = config[\"api_key\"]\n",
    "    log_path = root + \"/\" + config[\"log_path\"]\n",
    "    exe_log_path = root + \"/\" + config[\"exe_log_path\"]\n",
    "\n",
    "\n",
    "    log = Log()\n",
    "    global logging\n",
    "    logging = log.set_log(filepath = log_path, level = 2, freq = \"D\", interval = 50)\n",
    "\n",
    "    prompt = get_query(query_path, data_path, query_venv_path)\n",
    "\n",
    "    code, requirements = connect_gpt(openai, api_key, prompt)\n",
    "\n",
    "    save_file(code, requirements, python_path, requirements_path)\n",
    "\n",
    "    log.shutdown()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a07fcf0145f94b3f971c13d061528107de20ab7b779375f96dab9bbac6a85db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
